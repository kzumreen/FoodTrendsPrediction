{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kzumreen/FoodTrendsPrediction/blob/main/pytrends_eda_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9168eff",
      "metadata": {
        "id": "c9168eff"
      },
      "source": [
        "# PyTrends EDA Template\n",
        "\n",
        "This notebook pulls Google Trends data via **PyTrends** (or uses synthetic data if offline), performs exploratory data analysis (descriptive statistics + visualizations), and saves outputs. It is designed to satisfy the EDA rubric for your DAT 490 project."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b4130c",
      "metadata": {
        "id": "32b4130c"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install required packages (run in terminal):\n",
        "\n",
        "```bash\n",
        "pip install pytrends pandas matplotlib seaborn plotly nbformat\n",
        "```\n",
        "\n",
        "If pytrends or network access is unavailable, the notebook falls back to a synthetic dataset for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1a268c",
      "metadata": {
        "id": "9c1a268c"
      },
      "outputs": [],
      "source": [
        "# Optional: install packages from the notebook\n",
        "# !pip install pytrends pandas matplotlib seaborn plotly nbformat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89ebce5",
      "metadata": {
        "id": "f89ebce5"
      },
      "outputs": [],
      "source": [
        "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
        "from datetime import datetime\n",
        "OUTPUT_DIR = 'pytrends_eda_outputs'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "sns.set(style='whitegrid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50dad64e",
      "metadata": {
        "id": "50dad64e"
      },
      "outputs": [],
      "source": [
        "def synthetic_trends(keywords, start='2021-01-01', end='2025-10-01', seed=42):\n",
        "    rng = pd.date_range(start=start, end=end, freq='W-SUN')\n",
        "    np.random.seed(seed)\n",
        "    data = pd.DataFrame(index=rng)\n",
        "    for kw in keywords:\n",
        "        base = np.random.poisson(lam=5, size=len(rng)).astype(float)\n",
        "        spikes = np.zeros(len(rng))\n",
        "        for i in range(3):\n",
        "            loc = np.random.randint(0, len(rng))\n",
        "            width = np.random.randint(1, 6)\n",
        "            height = np.random.randint(30, 90)\n",
        "            start_i = max(0, loc - width)\n",
        "            end_i = min(len(rng), loc + width)\n",
        "            spikes[start_i:end_i] += np.linspace(height, 0, end_i-start_i)\n",
        "        series = (base + spikes).clip(0, 100)\n",
        "        series = (series / series.max() * 100) if series.max() > 0 else series\n",
        "        data[kw] = series.round(1)\n",
        "    return data\n",
        "\n",
        "def descriptive_stats(df):\n",
        "    stats = df.describe().T\n",
        "    stats['skew'] = df.skew()\n",
        "    stats['kurtosis'] = df.kurtosis()\n",
        "    return stats\n",
        "\n",
        "def save_fig(fig, name):\n",
        "    out = os.path.join(OUTPUT_DIR, name)\n",
        "    fig.savefig(out, dpi=150, bbox_inches='tight')\n",
        "    print('Saved', out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c6568d",
      "metadata": {
        "id": "76c6568d"
      },
      "source": [
        "## Fetch Google Trends Data\n",
        "Edit `keywords`, `timeframe`, `geo`, and `gprop` below. If pytrends is unavailable, the notebook will use synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba2328fa",
      "metadata": {
        "id": "ba2328fa"
      },
      "outputs": [],
      "source": [
        "keywords = ['baked feta pasta', 'matcha', 'mushroom coffee']\n",
        "timeframe = '2021-01-01 2025-10-01'\n",
        "geo = 'US'\n",
        "gprop = ''\n",
        "\n",
        "def fetch_google_trends(keywords, timeframe='2021-01-01 2025-10-01', geo='US', gprop=''):\n",
        "    try:\n",
        "        from pytrends.request import TrendReq\n",
        "    except Exception as e:\n",
        "        print('pytrends import failed:', e)\n",
        "        return None\n",
        "    try:\n",
        "        pytrends = TrendReq(hl='en-US', tz=360)\n",
        "        pytrends.build_payload(kw_list=keywords, timeframe=timeframe, geo=geo, gprop=gprop)\n",
        "        data = pytrends.interest_over_time()\n",
        "        if data is None or data.empty:\n",
        "            return None\n",
        "        if 'isPartial' in data.columns:\n",
        "            data = data.drop(columns=['isPartial'])\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print('pytrends fetch error:', e)\n",
        "        return None\n",
        "\n",
        "data = fetch_google_trends(keywords, timeframe=timeframe, geo=geo, gprop=gprop)\n",
        "source = 'pytrends' if data is not None else 'synthetic'\n",
        "if data is None:\n",
        "    data = synthetic_trends(keywords, start=timeframe.split()[0], end=timeframe.split()[1])\n",
        "print('Data source:', source)\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c155c8f8",
      "metadata": {
        "id": "c155c8f8"
      },
      "source": [
        "## Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bed50d",
      "metadata": {
        "id": "36bed50d"
      },
      "outputs": [],
      "source": [
        "stats = descriptive_stats(data)\n",
        "stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e76ec4",
      "metadata": {
        "id": "49e76ec4"
      },
      "source": [
        "## Time-series Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1401083",
      "metadata": {
        "id": "a1401083"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "data.plot(ax=ax)\n",
        "ax.set_title('Search Interest Over Time (0-100 Index)')\n",
        "ax.set_ylabel('Relative Search Interest')\n",
        "ax.set_xlabel('Date')\n",
        "plt.legend(title='Keyword')\n",
        "save_fig(fig, 'fig_time_series.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dbc9154",
      "metadata": {
        "id": "0dbc9154"
      },
      "source": [
        "## Rolling Mean (8-week)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a27013",
      "metadata": {
        "id": "95a27013"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "data.rolling(8).mean().plot(ax=ax)\n",
        "ax.set_title('8-week Rolling Mean of Search Interest')\n",
        "ax.set_ylabel('Rolling Mean (0-100)')\n",
        "ax.set_xlabel('Date')\n",
        "save_fig(fig, 'fig_rolling_8.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "132f4754",
      "metadata": {
        "id": "132f4754"
      },
      "source": [
        "## Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac6c13b8",
      "metadata": {
        "id": "ac6c13b8"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(data.corr(), annot=True, cmap='vlag', center=0, ax=ax)\n",
        "ax.set_title('Correlation Between Keywords (Search Interest Index)')\n",
        "save_fig(fig, 'fig_correlation.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8765577",
      "metadata": {
        "id": "e8765577"
      },
      "source": [
        "## Related Queries (Optional)\n",
        "If PyTrends is available, run this cell to fetch related queries for each keyword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca98030",
      "metadata": {
        "id": "bca98030"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from pytrends.request import TrendReq\n",
        "    pytrends = TrendReq(hl='en-US', tz=360)\n",
        "    pytrends.build_payload(keywords, timeframe=timeframe, geo=geo, gprop=gprop)\n",
        "    related = pytrends.related_queries()\n",
        "    for k in keywords:\n",
        "        print('\\n==', k, '==')\n",
        "        top = related.get(k, {}).get('top')\n",
        "        rising = related.get(k, {}).get('rising')\n",
        "        print('Top queries:')\n",
        "        display(top.head() if top is not None else 'None')\n",
        "        print('Rising queries:')\n",
        "        display(rising.head() if rising is not None else 'None')\n",
        "except Exception as e:\n",
        "    print('Skipping related queries (pytrends not available):', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b9b147",
      "metadata": {
        "id": "74b9b147"
      },
      "outputs": [],
      "source": [
        "\n",
        "html = \"\"\"<html><head><meta charset='utf-8'><title>PyTrends EDA Report</title></head><body>\n",
        "<h1>PyTrends EDA Report</h1>\n",
        "<p>Generated: %s</p>\n",
        "<h2>Keywords</h2><ul>%s</ul>\n",
        "<h2>Notes</h2><p>Data source: %s. Outputs saved in %s.</p>\n",
        "<h2>Figures</h2>\n",
        "<img src='fig_time_series.png' style='max-width:900px;width:100%;'/>\n",
        "<img src='fig_rolling_8.png' style='max-width:900px;width:100%;'/>\n",
        "<img src='fig_correlation.png' style='max-width:900px;width:100%;'/>\n",
        "</body></html>\"\"\" % (datetime.now().isoformat(), ''.join([f\"<li>{k}</li>\" for k in keywords]), source, OUTPUT_DIR)\n",
        "\n",
        "with open(os.path.join(OUTPUT_DIR, 'eda_report.html'), 'w', encoding='utf-8') as f:\n",
        "    f.write(html)\n",
        "print('Saved simple HTML report to', os.path.join(OUTPUT_DIR, 'eda_report.html'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a924c992",
      "metadata": {
        "id": "a924c992"
      },
      "source": [
        "## Next steps & Tips\n",
        "\n",
        "- Overlay timestamps of viral posts to explain spikes.\n",
        "- Combine with YouTube/Reddit timestamps for causal linkage.\n",
        "- Consider resampling frequency and handling timezone differences."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}