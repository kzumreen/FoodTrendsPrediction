{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dcc65b",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kzumreen/FoodTrendsPrediction/blob/main/pytrends_eda_notebook_info.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9168eff",
   "metadata": {
    "id": "c9168eff"
   },
   "source": [
    "# PyTrends EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4130c",
   "metadata": {
    "id": "32b4130c"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1a268c",
   "metadata": {
    "id": "9c1a268c"
   },
   "outputs": [],
   "source": [
    "#!pip install pytrends\n",
    "#!pip install statsmodels\n",
    "#!pip install plotly pycountry wordcloud\n",
    "#!pip install pycountry pycountry_convert plotly\n",
    "\n",
    "# Cell 1 — imports & palette\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytrends.request import TrendReq\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14,5)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Your color palette\n",
    "colors = {\n",
    "    'dubai-chocolate':'#3A1F04',\n",
    "    'feta-pasta':'#B90E0A',\n",
    "    'matcha':'#32612D',\n",
    "    'airfryer':'#D2691E'\n",
    "}\n",
    "def trend_color(tid): \n",
    "    return colors.get(tid, '#1f77b4')\n",
    "\n",
    "# normalize Trend_ID helper (same rules you specified)\n",
    "import re\n",
    "def normalize_trend_id(name: str) -> str:\n",
    "    if pd.isna(name): return ''\n",
    "    s = str(name).lower().strip()\n",
    "    s = re.sub(r'[_\\s]+','-', s)\n",
    "    s = re.sub(r'[^a-z0-9\\-]','', s)\n",
    "    s = re.sub(r'-{2,}','-', s)\n",
    "    return s.strip('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154fc4c9-42a1-47c6-8fd9-32bdc761e35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trends to fetch: ['airfryer', 'dubai chocolate', 'feta pasta', 'matcha']\n",
      "Timeframe: 2019-01-01 2025-10-01\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — config\n",
    "pytrends = TrendReq(hl='en-US', tz=360)  # adjust tz if you want\n",
    "\n",
    "# Replace with your actual list of trend names (display names) if different\n",
    "TREND_LIST = [\n",
    "    \"airfryer\",\n",
    "    \"dubai chocolate\",\n",
    "    \"feta pasta\",\n",
    "    \"matcha\"\n",
    "]\n",
    "\n",
    "# Timeframe: change as needed. Use 'today 5-y' or explicit \"YYYY-MM-DD YYYY-MM-DD\"\n",
    "TIMEFRAME = \"2019-01-01 2025-10-01\"  \n",
    "\n",
    "print(\"Trends to fetch:\", TREND_LIST)\n",
    "print(\"Timeframe:\", TIMEFRAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e380d277-758e-4e87-8aae-00934c4deed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n",
      "C:\\Anaconda\\Lib\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n",
      "C:\\Anaconda\\Lib\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series rows fetched: 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trend Name</th>\n",
       "      <th>Trend_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airfryer</td>\n",
       "      <td>airfryer</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airfryer</td>\n",
       "      <td>airfryer</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airfryer</td>\n",
       "      <td>airfryer</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airfryer</td>\n",
       "      <td>airfryer</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airfryer</td>\n",
       "      <td>airfryer</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trend Name  Trend_ID        Date Region  Interest\n",
       "0   airfryer  airfryer  2019-01-01  WORLD      19.0\n",
       "1   airfryer  airfryer  2019-02-01  WORLD      15.0\n",
       "2   airfryer  airfryer  2019-03-01  WORLD      14.0\n",
       "3   airfryer  airfryer  2019-04-01  WORLD      12.0\n",
       "4   airfryer  airfryer  2019-05-01  WORLD      13.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 — fetch interest_over_time (daily)\n",
    "rows = []\n",
    "for tn in TREND_LIST:\n",
    "    try:\n",
    "        pytrends.build_payload([tn], timeframe=TIMEFRAME, geo='')\n",
    "        df_ot = pytrends.interest_over_time()\n",
    "        if df_ot.empty:\n",
    "            print(f\"No time-series for {tn}\")\n",
    "            continue\n",
    "        # df_ot indexed by Timestamp; column name is the original term\n",
    "        for dt, r in df_ot.iterrows():\n",
    "            val = r.get(tn, np.nan)\n",
    "            rows.append({\n",
    "                \"Trend Name\": tn,\n",
    "                \"Trend_ID\": normalize_trend_id(tn),\n",
    "                \"Date\": dt.date(),   # store as date for now\n",
    "                \"Region\": \"WORLD\",\n",
    "                \"Interest\": float(val) if not pd.isna(val) else np.nan\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching time-series for\", tn, e)\n",
    "\n",
    "df_time = pd.DataFrame(rows)\n",
    "print(\"Time-series rows fetched:\", len(df_time))\n",
    "df_time.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d97afd-42ee-447e-ab88-f343b59c959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom countries selected: {'US': 'United States', 'IND': 'India', 'UAE': 'United Arab Emirates', 'SK': 'South Korea', 'UK': 'United Kingdom'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — choose the countries you want region-level maps for\n",
    "# Use ISO2 codes (pytrends expects geo as ISO2 for country-level region fetch)\n",
    "# Common codes: US, IN, AE, KR, GB, AU, CA, JP, DE, FR\n",
    "CUSTOM_COUNTRIES = {\n",
    "    'US': 'United States',\n",
    "    'IND': 'India',\n",
    "    'UAE': 'United Arab Emirates',\n",
    "    'SK': 'South Korea',\n",
    "    'UK': 'United Kingdom',\n",
    "    # add more if you like, e.g. 'AU':'Australia', 'CA':'Canada'\n",
    "}\n",
    "\n",
    "# How many top subregions to show in bar charts / heatmaps\n",
    "TOP_N_REGIONS = 6\n",
    "\n",
    "# US state name -> USPS abbreviation mapping (for choropleth)\n",
    "US_STATE_ABBREV = {\n",
    " 'Alabama':'AL','Alaska':'AK','Arizona':'AZ','Arkansas':'AR','California':'CA','Colorado':'CO','Connecticut':'CT',\n",
    " 'Delaware':'DE','District of Columbia':'DC','Florida':'FL','Georgia':'GA','Hawaii':'HI','Idaho':'ID','Illinois':'IL',\n",
    " 'Indiana':'IN','Iowa':'IA','Kansas':'KS','Kentucky':'KY','Louisiana':'LA','Maine':'ME','Maryland':'MD','Massachusetts':'MA',\n",
    " 'Michigan':'MI','Minnesota':'MN','Mississippi':'MS','Missouri':'MO','Montana':'MT','Nebraska':'NE','Nevada':'NV','New Hampshire':'NH',\n",
    " 'New Jersey':'NJ','New Mexico':'NM','New York':'NY','North Carolina':'NC','North Dakota':'ND','Ohio':'OH','Oklahoma':'OK',\n",
    " 'Oregon':'OR','Pennsylvania':'PA','Rhode Island':'RI','South Carolina':'SC','South Dakota':'SD','Tennessee':'TN','Texas':'TX',\n",
    " 'Utah':'UT','Vermont':'VT','Virginia':'VA','Washington':'WA','West Virginia':'WV','Wisconsin':'WI','Wyoming':'WY'\n",
    "}\n",
    "\n",
    "print(\"Custom countries selected:\", CUSTOM_COUNTRIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07fb0884-3e75-43ba-8c77-336408fc640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting robust subregion fetch (fixed TrendReq)...\n",
      "\n",
      "Fetching subregions for country: United States (US)\n",
      "  fetched 51 subregions for airfryer (timeframe=2019-01-01 2025-10-01)\n",
      "  fetched 51 subregions for dubai chocolate (timeframe=2019-01-01 2025-10-01)\n",
      "  fetched 51 subregions for feta pasta (timeframe=2019-01-01 2025-10-01)\n",
      "  fetched 51 subregions for matcha (timeframe=2019-01-01 2025-10-01)\n",
      "\n",
      "Fetching subregions for country: India (IND)\n",
      "   attempt 1 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED airfryer in India with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for airfryer in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED airfryer in India with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED dubai chocolate in India with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for dubai chocolate in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED dubai chocolate in India with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED feta pasta in India with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for feta pasta in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED feta pasta in India with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED matcha in India with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for matcha in IND: The request failed: Google returned a response with code 400\n",
      "  FAILED matcha in India with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "\n",
      "Fetching subregions for country: United Arab Emirates (UAE)\n",
      "   attempt 1 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED airfryer in United Arab Emirates with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for airfryer in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED airfryer in United Arab Emirates with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED dubai chocolate in United Arab Emirates with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for dubai chocolate in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED dubai chocolate in United Arab Emirates with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED feta pasta in United Arab Emirates with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for feta pasta in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED feta pasta in United Arab Emirates with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED matcha in United Arab Emirates with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for matcha in UAE: The request failed: Google returned a response with code 400\n",
      "  FAILED matcha in United Arab Emirates with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "\n",
      "Fetching subregions for country: South Korea (SK)\n",
      "  fetched 8 subregions for airfryer (timeframe=2019-01-01 2025-10-01)\n",
      "  fetched 8 subregions for dubai chocolate (timeframe=2019-01-01 2025-10-01)\n",
      "  fetched 8 subregions for feta pasta (timeframe=2019-01-01 2025-10-01)\n",
      "  fetched 8 subregions for matcha (timeframe=2019-01-01 2025-10-01)\n",
      "\n",
      "Fetching subregions for country: United Kingdom (UK)\n",
      "   attempt 1 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED airfryer in United Kingdom with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for airfryer in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED airfryer in United Kingdom with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED dubai chocolate in United Kingdom with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for dubai chocolate in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED dubai chocolate in United Kingdom with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED feta pasta in United Kingdom with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for feta pasta in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED feta pasta in United Kingdom with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED matcha in United Kingdom with timeframe 2019-01-01 2025-10-01: The request failed: Google returned a response with code 400\n",
      "   attempt 1 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 2 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 3 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "   attempt 4 failed for matcha in UK: The request failed: Google returned a response with code 400\n",
      "  FAILED matcha in United Kingdom with timeframe today 12-m: The request failed: Google returned a response with code 400\n",
      "\n",
      "Total subregion rows fetched: 236\n",
      "Total failures (country, trend) pairs: 12\n",
      "Failures (sample up to 20): [('IND', 'India', 'airfryer'), ('IND', 'India', 'dubai chocolate'), ('IND', 'India', 'feta pasta'), ('IND', 'India', 'matcha'), ('UAE', 'United Arab Emirates', 'airfryer'), ('UAE', 'United Arab Emirates', 'dubai chocolate'), ('UAE', 'United Arab Emirates', 'feta pasta'), ('UAE', 'United Arab Emirates', 'matcha'), ('UK', 'United Kingdom', 'airfryer'), ('UK', 'United Kingdom', 'dubai chocolate'), ('UK', 'United Kingdom', 'feta pasta'), ('UK', 'United Kingdom', 'matcha')]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '\\mnt\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m    100\u001b[0m out_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/df_subregions_robust.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 101\u001b[0m df_subregions\u001b[38;5;241m.\u001b[39mto_csv(out_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved df_subregions to\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_csv)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '\\mnt\\data'"
     ]
    }
   ],
   "source": [
    "# Robust fetch for subregions (fixed TrendReq init)\n",
    "import time\n",
    "import random\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "# Correct TrendReq initialization:\n",
    "# - timeout passed as timeout= (not inside requests_args)\n",
    "# - headers inside requests_args only\n",
    "pytrends = TrendReq(\n",
    "    hl='en-US',\n",
    "    tz=360,\n",
    "    timeout=(10, 25),  # tuple allowed: (connect timeout, read timeout)\n",
    "    requests_args={\n",
    "        'headers': {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                          'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                          'Chrome/115.0 Safari/537.36'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# parameters\n",
    "PRIMARY_TIMEFRAME = TIMEFRAME  # from your earlier cell, e.g. \"2019-01-01 2025-10-01\"\n",
    "FALLBACK_TIMEFRAME = 'today 12-m'   # usually accepted for region queries\n",
    "MAX_RETRIES = 4\n",
    "SLEEP_BETWEEN_CALLS = (1.0, 2.5)  # random sleep range in seconds\n",
    "\n",
    "region_rows = []\n",
    "failures = []\n",
    "\n",
    "def safe_interest_by_region(trend_name, geo_iso2, timeframe):\n",
    "    \"\"\"Call interest_by_region with retries; return DataFrame or raise exception.\"\"\"\n",
    "    last_exc = None\n",
    "    for attempt in range(1, MAX_RETRIES+1):\n",
    "        try:\n",
    "            pytrends.build_payload([trend_name], timeframe=timeframe, geo=geo_iso2)\n",
    "            df_sub = pytrends.interest_by_region(resolution='REGION', inc_low_vol=True, inc_geo_code=False)\n",
    "            return df_sub\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            err_msg = str(e)\n",
    "            print(f\"   attempt {attempt} failed for {trend_name} in {geo_iso2}: {err_msg}\")\n",
    "            # exponential backoff + jitter\n",
    "            sleep_time = min((2 ** (attempt-1)) + random.uniform(0.5, 1.5), 10)\n",
    "            time.sleep(sleep_time)\n",
    "    # all retries exhausted\n",
    "    raise last_exc\n",
    "\n",
    "print(\"Starting robust subregion fetch (fixed TrendReq)...\")\n",
    "\n",
    "for iso2, country_name in CUSTOM_COUNTRIES.items():\n",
    "    print(f\"\\nFetching subregions for country: {country_name} ({iso2})\")\n",
    "    for tn in TREND_LIST:\n",
    "        success = False\n",
    "        # Try primary timeframe first, then fallback\n",
    "        for timeframe_try in (PRIMARY_TIMEFRAME, FALLBACK_TIMEFRAME):\n",
    "            try:\n",
    "                df_sub = safe_interest_by_region(tn, iso2, timeframe_try)\n",
    "                if df_sub is None or df_sub.empty:\n",
    "                    # Received empty result; treat as failure for this timeframe\n",
    "                    print(f\"  empty response for {tn} in {country_name} with timeframe {timeframe_try}\")\n",
    "                    continue\n",
    "                # success: collect rows\n",
    "                for subregion_name, row in df_sub.iterrows():\n",
    "                    val = row.get(tn, np.nan)\n",
    "                    region_rows.append({\n",
    "                        \"Trend Name\": tn,\n",
    "                        \"Trend_ID\": normalize_trend_id(tn),\n",
    "                        \"Country_ISO2\": iso2,\n",
    "                        \"Country_Name\": country_name,\n",
    "                        \"Subregion\": subregion_name,\n",
    "                        \"Date\": pd.NaT,\n",
    "                        \"Interest\": float(val) if not pd.isna(val) else np.nan,\n",
    "                        \"Timeframe_Used\": timeframe_try\n",
    "                    })\n",
    "                print(f\"  fetched {len(df_sub)} subregions for {tn} (timeframe={timeframe_try})\")\n",
    "                success = True\n",
    "                # polite pause between trend calls\n",
    "                time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))\n",
    "                break\n",
    "            except Exception as e:\n",
    "                msg = str(e)\n",
    "                print(f\"  FAILED {tn} in {country_name} with timeframe {timeframe_try}: {msg}\")\n",
    "                # try next timeframe (fallback) or record failure later\n",
    "                continue\n",
    "\n",
    "        if not success:\n",
    "            failures.append((iso2, country_name, tn))\n",
    "            # small extra pause before next trend to reduce chance of blocks\n",
    "            time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))\n",
    "\n",
    "# Build DataFrame\n",
    "df_subregions = pd.DataFrame(region_rows)\n",
    "print(\"\\nTotal subregion rows fetched:\", len(df_subregions))\n",
    "print(\"Total failures (country, trend) pairs:\", len(failures))\n",
    "if failures:\n",
    "    print(\"Failures (sample up to 20):\", failures[:20])\n",
    "\n",
    "# Save results\n",
    "out_csv = \"/mnt/data/df_subregions_robust.csv\"\n",
    "df_subregions.to_csv(out_csv, index=False)\n",
    "print(\"Saved df_subregions to\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8f319-e36a-42fc-acb3-8cfc48e72b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
